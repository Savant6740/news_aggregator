name: ğŸ“° Daily News Digest

# Progressive update strategy:
#   09:00 IST â€” first run, publish whatever papers have already arrived
#   09:30â€“12:00 IST â€” every 30 min, check for newly arrived papers and update
#                     site only if something new was found
#   Stops early once all expected papers are present for the day
#   Sunday: 7 papers expected (Mint and Business Standard not published)
#
# How the gate works (no Telegram calls in the workflow):
#   The progress check reads only docs/digest_state.json (committed to repo).
#   If is_complete=true for today â†’ skip immediately (~10 seconds, no Python).
#   Otherwise â†’ always proceed to digest.py, which handles the Telegram scan
#   internally and exits cleanly on its own if nothing new has arrived.
#   This avoids the secret-masking bug that breaks inline Telegram calls.
#
# â”€â”€ Minutes budget â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7 schedule triggers/day Ã— 31 days = 217 potential runs/month
#
# Run types:
#   (A) Complete skip  â€” state says done today, shell check only   â†’  ~0.1 min
#   (B) No-op run      â€” digest.py finds nothing new, exits early  â†’  ~3 min
#   (C) Partial update â€” 1â€“3 new papers, extract + build + deploy  â†’ ~10 min
#   (D) Full first run â€” 7â€“9 papers at once                        â†’ ~18 min
#
# BEST CASE  â€” all papers arrive before 9am every day (31 days)
#   09:00 â†’ 1 full run (D=18)  +  6 complete skips (A=0.1Ã—6=0.6)
#   Daily: ~19 min  â†’  19 Ã— 31 = 589 min/month  âœ…
#
# AVERAGE CASE â€” papers trickle over 2â€“3 runs/day (31 days)
#   09:00 â†’ partial (C=10)  09:30 â†’ partial (C=10)  10:00 â†’ partial (C=10)
#   10:30â€“12:00 â†’ 4 complete skips (Aâ‰ˆ0)
#   Daily: ~30 min  â†’  30 Ã— 31 = 930 min/month  âœ…
#
# WORST CASE â€” papers arrive late, one per slot (31 days)
#   09:00 â†’ no-op (B=3)  then 5 Ã— partial (C=10)  then 1 complete skip (Aâ‰ˆ0)
#   Daily: ~53 min  â†’  53 Ã— 31 = 1643 min/month  âš ï¸  (only if EVERY day is worst)
#
# REALISTIC WORST â€” based on observed data (Feb): 1 late day in 7
#   6 average days (30 min) + 1 worst day (53 min) per week
#   Monthly: ~(26Ã—30 + 5Ã—53) = 1045 min/month  âœ…
#
# Safe cap: remove the 11:30 + 12:00 crons â†’ worst case ~40 min/day = 1240/month

on:
  schedule:
    - cron: '30 3 * * *'   # 09:00 IST = 03:30 UTC  â† first run of the day
    - cron: '0 4 * * *'    # 09:30 IST = 04:00 UTC
    - cron: '30 4 * * *'   # 10:00 IST = 04:30 UTC
    - cron: '0 5 * * *'    # 10:30 IST = 05:00 UTC
    - cron: '30 5 * * *'   # 11:00 IST = 05:30 UTC
    - cron: '0 6 * * *'    # 11:30 IST = 06:00 UTC
    - cron: '30 6 * * *'   # 12:00 IST = 06:30 UTC
  workflow_dispatch:
    inputs:
      note:
        description: 'Optional note (e.g. "all 9 papers confirmed")'
        required: false
        default: ''

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  digest:
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      # â”€â”€ Checkout first â€” needed to read state file â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: ğŸ“¥ Checkout repo
        uses: actions/checkout@v4

      # â”€â”€ Fast gate: pure shell, reads state file only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # No Python, no Telegram. Reads docs/digest_state.json which was committed
      # by the previous run. If today is already marked complete, bail in ~5 sec.
      # All Telegram interaction happens inside digest.py where secrets work fine.
      - name: ğŸ” Check if today is already complete
        id: gate
        run: |
          TODAY=$(TZ='Asia/Kolkata' date +'%Y-%m-%d')
          STATE_FILE="docs/digest_state.json"
          EVENT="${{ github.event_name }}"

          if [ "$EVENT" = "workflow_dispatch" ]; then
            echo "Manual trigger â€” always proceed."
            echo "proceed=true" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          if [ ! -f "$STATE_FILE" ]; then
            echo "No state file â€” first run ever, proceeding."
            echo "proceed=true" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          FILE_DATE=$(python3 -c "import json; d=json.load(open('$STATE_FILE')); print(d.get('date',''))" 2>/dev/null || echo "")
          IS_COMPLETE=$(python3 -c "import json; d=json.load(open('$STATE_FILE')); print(str(d.get('is_complete',False)).lower())" 2>/dev/null || echo "false")

          echo "State file: date=$FILE_DATE  is_complete=$IS_COMPLETE  today=$TODAY"

          if [ "$FILE_DATE" = "$TODAY" ] && [ "$IS_COMPLETE" = "true" ]; then
            echo "All papers already processed today â€” skipping."
            echo "proceed=false" >> "$GITHUB_OUTPUT"
          else
            echo "Not yet complete â€” proceeding to pipeline."
            echo "proceed=true" >> "$GITHUB_OUTPUT"
          fi

      # â”€â”€ Python + heavy deps only when we're actually going to run â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: ğŸ Set up Python 3.11
        if: steps.gate.outputs.proceed == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: ğŸ“¦ Cache pip dependencies
        if: steps.gate.outputs.proceed == 'true'
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: ğŸ“¦ Install Python dependencies
        if: steps.gate.outputs.proceed == 'true'
        run: pip install -r requirements.txt

      - name: ğŸ›  Install system dependencies (OCR)
        if: steps.gate.outputs.proceed == 'true'
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y poppler-utils tesseract-ocr libtesseract-dev

      # â”€â”€ Main pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # digest.py handles all intelligence internally:
      #   1. Reads digest_state.json â†’ knows what's already done today
      #   2. Scans Telegram for newly arrived papers (secrets work fine here)
      #   3. If nothing new â†’ exits cleanly with code 0, no site rebuild
      #   4. If new papers â†’ downloads, extracts, deduplicates, rebuilds site
      #   5. Writes updated digest_state.json (is_complete=true when all done)
      - name: ğŸ¤– Run digest pipeline
        if: steps.gate.outputs.proceed == 'true'
        env:
          GEMINI_API_KEY:    ${{ secrets.GEMINI_API_KEY }}
          TELEGRAM_API_ID:   ${{ secrets.TELEGRAM_API_ID }}
          TELEGRAM_API_HASH: ${{ secrets.TELEGRAM_API_HASH }}
          TELEGRAM_CHANNEL:  ${{ secrets.TELEGRAM_CHANNEL }}
          NOTIFY_BOT_TOKEN:  ${{ secrets.NOTIFY_BOT_TOKEN }}
          NOTIFY_CHAT_ID:    ${{ secrets.NOTIFY_CHAT_ID }}
          SITE_URL:          ${{ secrets.SITE_URL }}
        run: python3 digest.py

      # â”€â”€ Commit only if digest.py actually changed something â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # git diff --staged --quiet short-circuits the commit when digest.py
      # exited early (nothing new found) so Pages isn't redeployed needlessly.
      - name: ğŸ’¾ Commit site files + state
        if: steps.gate.outputs.proceed == 'true'
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add docs/index.html docs/digest.json docs/digest_state.json
          git diff --staged --quiet || git commit -m "ğŸ“° Digest update: $(TZ='Asia/Kolkata' date +'%d %b %Y %H:%M IST')"
          git push

      - name: ğŸ“¤ Upload docs/ as Pages artifact
        if: steps.gate.outputs.proceed == 'true'
        uses: actions/upload-pages-artifact@v3
        with:
          path: docs/

      - name: ğŸš€ Deploy to GitHub Pages
        if: steps.gate.outputs.proceed == 'true'
        uses: actions/deploy-pages@v4
        id: deployment

      - name: ğŸ“¤ Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: digest-logs
          path: "*.log"
          retention-days: 3
